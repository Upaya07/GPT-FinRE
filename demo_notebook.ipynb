{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Banner Image -->\n",
        "\n",
        "\n",
        "<!-- Links -->\n",
        "<center>\n",
        "  <a href=\"https://arxiv.org/abs/2306.17519\" style=\"color: #06b6d4;\">Paper</a> â€¢\n",
        "  <a href=\"https://kdf-workshop.github.io/kdf23/shared_task\" style=\"color: #06b6d4;\">Competition</a>\n",
        "</center>\n",
        "\n",
        "# Learning To Retrieve Prompts for In-Context Learning ðŸ¤™\n",
        "\n",
        "Welcome!\n",
        "\n",
        "In this notebook and tutorial, we showcase our KDF SIGIR 2023 shared task solution which won 3rd rank overall.\n",
        "\n",
        "# Problem Statement\n",
        "To predict relation between given entities in sentence. The data is specific to Finance Domain.\n",
        "<center>\n",
        "<img src=\"https://refind-re.github.io/dist/pic/Intro.png\" width=\"80%\">\n",
        "</center>\n",
        "\n",
        "\n",
        "# Data\n",
        "<center>\n",
        "<img src=\"https://refind-re.github.io/plotting/barplot.png\" width=\"60%\">\n",
        "</center>\n",
        "# Labels\n",
        "<center>\n",
        "<img src=\"https://i.ibb.co/kMwymsy/Screenshot-2024-01-23-at-11-47-11-PM.png\" width=\"60%\">\n",
        "</center>\n",
        "\n",
        "# Our Solution\n",
        "<center>\n",
        "<img src=\"https://i.ibb.co/tQ0jGP3/Screenshot-2024-01-23-at-11-50-31-PM.png\" width=\"80%\">\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "dcx42iBLLN-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP2BAP0kSGkU",
        "outputId": "f02c15c0-9aff-43a9-9d02-30f70c663b55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.10.1+cu113 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.10.1+cu113\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.10.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM5OQPT48Vm4"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "import pickle\n",
        "import copy\n",
        "from random import shuffle\n",
        "ins_dic ={\"ORG-ORG\": \"org:org:agreement_with\twhen org enter or plan to enter into an agreement with org Y for matters like settlement\\n  license etc\\n  org:org:shares_of\twhen an org holds some shares of another org or it invests in the other org through IPO\\n  stocks\\n voting rights etc\\n  org:org:acquired_by\twhen an org is acquired by another org\\n  org:org:subsidiary_of\twhen an org is subsidiary of another org\",\"PERSON-UNIV\": \"pers:univ:attended\twhen a person attended a university as a student\",\"PERSON-ORG\": \"pers:org:employee_of\twhen a person is an employee of an organization\\n  pers:org:member_of\twhen a person is a member of an organization\", \"PERSON-TITLE\": \"pers:title:title\twhen a person has a title designation\", \"ORG-GPE\": \"org:gpe:formed_in\twhen an organization is formed on a certain date\\n  org:gpe:headquartered_in\twhen organization is headquartered in a location\\n  org:gpe:operations_in\twhen an organization has a office at a location or operates in a location\", \"ORG-MONEY\": \"org:money:revenue_of\twhen an organization reports revenue of given amount\\n  org:money:profit_of\twhen an organization reports profit of given amount\\n  org:money:loss_of\twhen an organization reports loss of given amount\\n  org:money:cost_of\twhen an organization has a costing of given amount\", \"ORG-DATE\": \"org:date:formed_on\twhen an organization was formed on a certain date\\n  org:date:acquired_on\twhen organization was aquired on a date\\n  pers:univ:employee_of\twhen a person is an employee of a university\", \"PERSON-ORG\":\"pers:org:founder_of\twhen a person is a founder of an organization\", \"PERSON-GOV_AGY\": \"pers:gov_agy:member_of\twhen a person is an employee of a government agency\"}\n",
        "\n",
        "\n",
        "handle = open('train_kv_map.pickle', 'rb')\n",
        "train_kv_map = pickle.load(handle)\n",
        "handle2 = open('random_kv_map.pickle', 'rb')\n",
        "random_kv_map = pickle.load(handle2)\n",
        "\n",
        "def add_random_examples(rel_grp_name,n):\n",
        "  results = []\n",
        "  result_p_list = []\n",
        "  dic_value = {}\n",
        "  all_possible_example_classes = random_kv_map[rel_grp_name]\n",
        "  rel_grp_name  = rel_grp_name.replace(\"PERSON\",\"pers\")\n",
        "  shuffle(all_possible_example_classes)\n",
        "  for pos in all_possible_example_classes:\n",
        "    if pos[0] in dic_value:\n",
        "      if len(dic_value[pos[0]])==n:\n",
        "        continue\n",
        "      dic_value[pos[0]] = dic_value[pos[0]] +[pos[1]]\n",
        "    else:\n",
        "      dic_value[pos[0]] = [pos[1]]\n",
        "  for k,v in dic_value.items():\n",
        "    results = results+v\n",
        "  final_st_prompt = \"\"\n",
        "  for r1 in results:\n",
        "    li2 = copy.deepcopy(r1)\n",
        "    del li2[\"sentence\"]\n",
        "    del li2[\"relation\"]\n",
        "    temp_p =  \"\\n\\n\"+r1[\"sentence\"]+\"\\n\"+str(li2)+\"\\nAnswer: \"+r1[\"relation\"]\n",
        "    result_p_list.append(temp_p)\n",
        "\n",
        "  return result_p_list\n",
        "def post_process_result(rel_grp_name):\n",
        "  rel_grp_name  = rel_grp_name.replace(\"PERSON\",\"pers\")\n",
        "  all_correct_results = []\n",
        "  rel1,rel2 = rel_grp_name.lower().split(\"-\")\n",
        "  data = json.load(open(\"pred.json\"))\n",
        "  prompt_temp = \"\"\n",
        "  raw_prompt = data[0][\"prompt\"]\n",
        "  all_prompt_examples = (raw_prompt.split(\"\\n\"))\n",
        "  for pe in all_prompt_examples:\n",
        "    flag_pe = False\n",
        "    key_to_check = pe.split(\"Can we say\")[0].strip()\n",
        "    if key_to_check not in train_kv_map:\n",
        "      continue\n",
        "    ans_dict = \"\"\n",
        "    for entry_i in train_kv_map[key_to_check]:\n",
        "      # print(entry_i[\"rel_group\"],rel_grp_name,\"CHECKKKKK\")\n",
        "      if entry_i[\"rel_group\"].replace(\"PERSON\",\"pers\") == rel_grp_name:\n",
        "        li3 = copy.deepcopy(entry_i)\n",
        "        del li3[\"relation\"]\n",
        "        ans_dict = str(li3)\n",
        "    if rel1+\":\"+rel2 in pe:\n",
        "      parsed_sen = key_to_check+\"\\n\"+ans_dict+\"\\nAnswer: \"+pe.split(\" \")[-1]\n",
        "      flag_pe = True\n",
        "    if rel2+\":\"+rel1 in pe:\n",
        "      parsed_sen = key_to_check+\"\\n\"+ans_dict+\"\\nAnswer: \"+pe.split(\" \")[-1]\n",
        "      flag_pe = True\n",
        "    # if \"no_relation\" in pe:\n",
        "    #   parsed_sen = key_to_check+\"\\n\"+ans_dict+\"\\nAnswer: \"+\"no_relation\"\n",
        "    #   flag_pe = True\n",
        "    if flag_pe:\n",
        "      # parsed_sen = pe.split(\"Can we say\")[0].strip()\n",
        "      all_correct_results.append(parsed_sen)\n",
        "  return (all_correct_results)\n",
        "  # i = data[0]\n",
        "def generate_ins(rel_grp_name):\n",
        "  base_i = \"INSTRUCTION\tI am a knowledgable person. I will solve the relation extraction task. Given the context and two entities, i will first consider whether the most precise relation between two entities belong to any following class, if yes i will output the most precise relation, otherwise output will be no_relation\"\n",
        "  base_i =base_i +\"\\n\"+ins_dic[rel_grp_name]\n",
        "  return base_i\n",
        "\n",
        "def generate_final_prompt():\n",
        "  res = post_process_result(test_data[\"rel_group\"])\n",
        "  random1 =add_random_examples(test_data[\"rel_group\"],5)\n",
        "  all_examples = res+random1\n",
        "  li4 = copy.deepcopy(test_data)\n",
        "  del li4[\"sentence\"]\n",
        "  del li4[\"relation\"]\n",
        "  pmt = \"\\n\".join(all_examples) + \"\\n\\n\"+test_data[\"sentence\"]+\"\\n\"+str(li4)+\"\\nAnswer: \"\n",
        "  ins = generate_ins(test_data[\"rel_group\"])\n",
        "  return pmt, ins\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd5DwZqLwnB8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "test_data = {\"sentence\": \"Pursuant to the Merger Agreement , UnitedHealth Group has agreed to acquire all of the outstanding shares of Surgical Care Affiliates , Inc. s common stock for $ 57.00 per share , to be funded with a combination of cash and UnitedHealth Group common stock , as set forth in the Merger Agreement .\", \"rel_group\": \"ORG-ORG\", \"relation\": \"org:org:acquired_by\", \"ORG_1\": \"Surgical Care Affiliates , Inc. s\", \"ORG_2\": \"UnitedHealth Group\"}\n",
        "f1 = open (\"test_kdf.json\",\"w\")\n",
        "f1.write(json.dumps(test_data))\n",
        "f1.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "827_4W_vYloi",
        "outputId": "ed28ca86-0d5e-4244-cdc0-1f3c71d33151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/icl-ceil/dense_retriever_new.py:246: UserWarning: \n",
            "The version_base parameter is not specified.\n",
            "Please specify a compatability version level, or None.\n",
            "Will assume defaults for version 1.1\n",
            "  @hydra.main(config_path=\"configs\", config_name=\"dense_retriever\")\n",
            "[2024-01-23 17:27:27,600][__main__][INFO] - {'output_file': 'output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64/train_retrieved.json', 'num_candidates': 1, 'num_ice': 50, 'task_name': 'mrpc', 'batch_size': 64, 'model_name': 'bert-base-uncased', 'faiss_index': 'output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64/index', 'pretrained_model_path': 'output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64', 'dpp_search': True, 'dpp_topk': 100, 'mode': 'cand_random', 'dataset_reader': {'_target_': 'src.dataset_readers.base_dsr.BaseDatasetReader', 'task_name': '${task_name}', 'model_name': '${model_name}', 'field': 'q', 'dataset_split': 'test', 'dataset_path': None, 'ds_size': None}, 'index_reader': {'_target_': 'src.dataset_readers.index_dsr.IndexDatasetReader', 'task_name': '${task_name}', 'model_name': '${model_name}', 'field': 'q', 'dataset_split': 'train', 'dataset_path': 'index_data/mrpc/index_dataset.json', 'ds_size': None}, 'model_config': {'_target_': 'src.models.biencoder.BiEncoderConfig', 'q_model_name': '${model_name}', 'ctx_model_name': '${model_name}', 'norm_embed': False, 'scale_factor': 0.1}}\n",
            "2024-01-23 17:27:27.889948: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-23 17:27:27.889991: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-23 17:27:27.891612: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-23 17:27:29.112239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-01-23 17:27:29,618][numexpr.utils][INFO] - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
            "[2024-01-23 17:27:29,618][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.\n",
            "[2024-01-23 17:27:30,201][datasets][INFO] - PyTorch version 2.1.0+cu121 available.\n",
            "[2024-01-23 17:27:30,202][datasets][INFO] - TensorFlow version 2.15.0 available.\n",
            "[2024-01-23 17:27:30,203][datasets][INFO] - JAX version 0.4.23 available.\n",
            "Map: 100% 1/1 [00:00<00:00, 78.36 examples/s]\n",
            "Some weights of BiEncoder were not initialized from the model checkpoint at output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64 and are newly initialized: ['ctx_model.encoder.layer.11.intermediate.dense.weight', 'ctx_model.encoder.layer.4.attention.self.value.weight', 'ctx_model.encoder.layer.0.attention.self.value.bias', 'ctx_model.encoder.layer.11.attention.output.dense.bias', 'ctx_model.encoder.layer.7.intermediate.dense.bias', 'ctx_model.encoder.layer.0.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.9.attention.self.value.weight', 'ctx_model.encoder.layer.3.output.dense.weight', 'ctx_model.encoder.layer.8.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.4.attention.output.dense.weight', 'ctx_model.encoder.layer.3.attention.self.key.bias', 'ctx_model.encoder.layer.5.output.LayerNorm.bias', 'ctx_model.encoder.layer.6.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.2.attention.self.query.bias', 'ctx_model.encoder.layer.0.output.LayerNorm.weight', 'ctx_model.encoder.layer.4.attention.output.LayerNorm.bias', 'ctx_model.embeddings.token_type_embeddings.weight', 'ctx_model.encoder.layer.3.attention.self.value.weight', 'ctx_model.encoder.layer.7.attention.self.query.weight', 'ctx_model.encoder.layer.8.attention.self.value.bias', 'ctx_model.encoder.layer.5.attention.self.query.weight', 'ctx_model.encoder.layer.9.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.10.intermediate.dense.bias', 'ctx_model.encoder.layer.3.output.dense.bias', 'ctx_model.encoder.layer.0.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.5.output.dense.bias', 'ctx_model.encoder.layer.1.attention.self.value.bias', 'ctx_model.encoder.layer.0.attention.output.dense.bias', 'ctx_model.encoder.layer.2.output.dense.bias', 'ctx_model.encoder.layer.2.attention.self.key.bias', 'ctx_model.encoder.layer.9.intermediate.dense.bias', 'ctx_model.encoder.layer.11.attention.self.query.weight', 'ctx_model.encoder.layer.8.attention.self.query.bias', 'ctx_model.encoder.layer.1.attention.self.key.bias', 'ctx_model.encoder.layer.11.attention.self.query.bias', 'ctx_model.encoder.layer.9.attention.self.key.bias', 'ctx_model.encoder.layer.11.attention.self.value.bias', 'ctx_model.encoder.layer.0.output.dense.weight', 'ctx_model.embeddings.position_embeddings.weight', 'ctx_model.encoder.layer.9.attention.self.query.bias', 'ctx_model.encoder.layer.2.attention.self.value.weight', 'ctx_model.encoder.layer.5.attention.self.query.bias', 'ctx_model.encoder.layer.3.attention.output.dense.bias', 'ctx_model.encoder.layer.6.attention.self.value.weight', 'ctx_model.encoder.layer.1.attention.self.value.weight', 'ctx_model.encoder.layer.8.attention.self.value.weight', 'ctx_model.encoder.layer.4.intermediate.dense.weight', 'ctx_model.encoder.layer.4.attention.self.key.weight', 'ctx_model.encoder.layer.1.attention.output.dense.bias', 'ctx_model.encoder.layer.7.attention.self.key.weight', 'ctx_model.encoder.layer.11.attention.self.key.weight', 'ctx_model.encoder.layer.5.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.10.output.LayerNorm.weight', 'ctx_model.encoder.layer.10.attention.self.key.weight', 'ctx_model.embeddings.LayerNorm.bias', 'ctx_model.encoder.layer.1.attention.self.key.weight', 'ctx_model.encoder.layer.1.output.LayerNorm.weight', 'ctx_model.encoder.layer.4.attention.self.value.bias', 'ctx_model.encoder.layer.4.output.LayerNorm.bias', 'ctx_model.encoder.layer.9.output.LayerNorm.weight', 'ctx_model.encoder.layer.9.intermediate.dense.weight', 'ctx_model.encoder.layer.11.attention.output.dense.weight', 'ctx_model.encoder.layer.7.output.dense.weight', 'ctx_model.encoder.layer.7.attention.output.dense.bias', 'ctx_model.encoder.layer.7.intermediate.dense.weight', 'ctx_model.encoder.layer.2.output.dense.weight', 'ctx_model.encoder.layer.10.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.8.attention.self.key.bias', 'ctx_model.pooler.dense.weight', 'ctx_model.encoder.layer.6.output.LayerNorm.weight', 'ctx_model.encoder.layer.6.output.dense.bias', 'ctx_model.encoder.layer.6.intermediate.dense.bias', 'ctx_model.encoder.layer.5.output.dense.weight', 'ctx_model.encoder.layer.1.intermediate.dense.weight', 'ctx_model.encoder.layer.6.attention.self.query.weight', 'ctx_model.encoder.layer.10.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.2.intermediate.dense.weight', 'ctx_model.encoder.layer.10.intermediate.dense.weight', 'ctx_model.encoder.layer.6.intermediate.dense.weight', 'ctx_model.encoder.layer.9.attention.output.dense.bias', 'ctx_model.encoder.layer.11.output.LayerNorm.weight', 'ctx_model.encoder.layer.8.intermediate.dense.weight', 'ctx_model.encoder.layer.3.attention.self.value.bias', 'ctx_model.encoder.layer.10.attention.self.value.weight', 'ctx_model.encoder.layer.11.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.0.intermediate.dense.weight', 'ctx_model.encoder.layer.3.intermediate.dense.bias', 'ctx_model.encoder.layer.1.intermediate.dense.bias', 'ctx_model.encoder.layer.2.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.0.attention.self.query.weight', 'ctx_model.pooler.dense.bias', 'ctx_model.encoder.layer.0.output.dense.bias', 'ctx_model.encoder.layer.2.attention.self.query.weight', 'ctx_model.encoder.layer.5.attention.output.dense.weight', 'ctx_model.encoder.layer.9.attention.self.key.weight', 'ctx_model.encoder.layer.10.attention.output.dense.weight', 'ctx_model.encoder.layer.6.attention.self.query.bias', 'ctx_model.encoder.layer.1.attention.output.dense.weight', 'ctx_model.encoder.layer.4.attention.self.query.bias', 'ctx_model.encoder.layer.6.output.LayerNorm.bias', 'ctx_model.encoder.layer.3.output.LayerNorm.weight', 'ctx_model.encoder.layer.4.output.dense.bias', 'ctx_model.encoder.layer.7.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.5.intermediate.dense.weight', 'ctx_model.encoder.layer.8.intermediate.dense.bias', 'ctx_model.encoder.layer.9.attention.output.dense.weight', 'ctx_model.encoder.layer.3.attention.self.key.weight', 'ctx_model.encoder.layer.2.output.LayerNorm.weight', 'ctx_model.encoder.layer.2.attention.output.dense.bias', 'ctx_model.encoder.layer.1.attention.self.query.weight', 'ctx_model.encoder.layer.7.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.10.attention.self.key.bias', 'ctx_model.encoder.layer.6.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.7.attention.self.query.bias', 'ctx_model.encoder.layer.1.output.LayerNorm.bias', 'ctx_model.encoder.layer.2.output.LayerNorm.bias', 'ctx_model.encoder.layer.4.output.dense.weight', 'ctx_model.encoder.layer.9.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.4.attention.output.dense.bias', 'ctx_model.encoder.layer.9.attention.self.value.bias', 'ctx_model.encoder.layer.7.output.LayerNorm.bias', 'ctx_model.encoder.layer.9.attention.self.query.weight', 'ctx_model.encoder.layer.1.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.10.attention.self.query.bias', 'ctx_model.encoder.layer.8.attention.self.key.weight', 'ctx_model.encoder.layer.7.attention.self.value.bias', 'ctx_model.encoder.layer.2.intermediate.dense.bias', 'ctx_model.encoder.layer.0.attention.self.value.weight', 'ctx_model.encoder.layer.2.attention.output.dense.weight', 'ctx_model.encoder.layer.5.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.0.output.LayerNorm.bias', 'ctx_model.encoder.layer.2.attention.self.value.bias', 'ctx_model.encoder.layer.3.attention.self.query.weight', 'ctx_model.encoder.layer.7.output.LayerNorm.weight', 'ctx_model.encoder.layer.1.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.11.output.dense.bias', 'ctx_model.encoder.layer.11.attention.self.key.bias', 'ctx_model.encoder.layer.4.intermediate.dense.bias', 'ctx_model.encoder.layer.3.attention.self.query.bias', 'ctx_model.encoder.layer.2.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.4.output.LayerNorm.weight', 'ctx_model.encoder.layer.8.output.LayerNorm.bias', 'ctx_model.encoder.layer.6.attention.output.dense.weight', 'ctx_model.encoder.layer.10.attention.output.dense.bias', 'ctx_model.encoder.layer.0.intermediate.dense.bias', 'ctx_model.encoder.layer.11.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.0.attention.output.dense.weight', 'ctx_model.encoder.layer.10.output.dense.weight', 'ctx_model.encoder.layer.5.attention.self.value.weight', 'ctx_model.encoder.layer.9.output.dense.weight', 'ctx_model.encoder.layer.1.output.dense.bias', 'ctx_model.encoder.layer.6.output.dense.weight', 'ctx_model.encoder.layer.9.output.dense.bias', 'ctx_model.encoder.layer.5.attention.self.value.bias', 'ctx_model.encoder.layer.0.attention.self.key.weight', 'ctx_model.encoder.layer.3.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.1.attention.self.query.bias', 'ctx_model.encoder.layer.3.attention.output.dense.weight', 'ctx_model.encoder.layer.3.attention.output.LayerNorm.bias', 'ctx_model.encoder.layer.8.output.dense.weight', 'ctx_model.encoder.layer.9.output.LayerNorm.bias', 'ctx_model.encoder.layer.5.attention.self.key.bias', 'ctx_model.encoder.layer.7.attention.output.dense.weight', 'ctx_model.encoder.layer.10.output.LayerNorm.bias', 'ctx_model.encoder.layer.0.attention.self.key.bias', 'ctx_model.encoder.layer.11.output.dense.weight', 'ctx_model.encoder.layer.3.output.LayerNorm.bias', 'ctx_model.encoder.layer.8.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.5.intermediate.dense.bias', 'ctx_model.encoder.layer.4.attention.output.LayerNorm.weight', 'ctx_model.encoder.layer.0.attention.self.query.bias', 'ctx_model.encoder.layer.2.attention.self.key.weight', 'ctx_model.encoder.layer.8.output.LayerNorm.weight', 'ctx_model.encoder.layer.11.output.LayerNorm.bias', 'ctx_model.encoder.layer.4.attention.self.query.weight', 'ctx_model.encoder.layer.8.output.dense.bias', 'ctx_model.encoder.layer.8.attention.self.query.weight', 'ctx_model.encoder.layer.5.attention.self.key.weight', 'ctx_model.embeddings.LayerNorm.weight', 'ctx_model.encoder.layer.7.attention.self.key.bias', 'ctx_model.encoder.layer.10.attention.self.value.bias', 'ctx_model.encoder.layer.7.attention.self.value.weight', 'ctx_model.encoder.layer.5.attention.output.dense.bias', 'ctx_model.encoder.layer.8.attention.output.dense.weight', 'ctx_model.encoder.layer.6.attention.self.key.weight', 'ctx_model.encoder.layer.5.output.LayerNorm.weight', 'ctx_model.encoder.layer.6.attention.output.dense.bias', 'ctx_model.encoder.layer.6.attention.self.key.bias', 'ctx_model.encoder.layer.6.attention.self.value.bias', 'ctx_model.encoder.layer.3.intermediate.dense.weight', 'ctx_model.encoder.layer.10.output.dense.bias', 'ctx_model.encoder.layer.10.attention.self.query.weight', 'ctx_model.encoder.layer.11.intermediate.dense.bias', 'ctx_model.encoder.layer.1.output.dense.weight', 'ctx_model.encoder.layer.11.attention.self.value.weight', 'ctx_model.encoder.layer.8.attention.output.dense.bias', 'ctx_model.encoder.layer.4.attention.self.key.bias', 'ctx_model.embeddings.word_embeddings.weight', 'ctx_model.encoder.layer.7.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[2024-01-23 17:27:36,731][__main__][INFO] - Loading faiss index from output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64/index\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/content/icl-ceil/inferencer.py:158: UserWarning: \n",
            "The version_base parameter is not specified.\n",
            "Please specify a compatability version level, or None.\n",
            "Will assume defaults for version 1.1\n",
            "  @hydra.main(config_path=\"configs\", config_name=\"inferencer\")\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'inferencer': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
            "  warnings.warn(msg, UserWarning)\n",
            "[2024-01-23 17:27:45,522][__main__][INFO] - {'model_config': {'model_type': 'hf', 'model': {'_target_': 'transformers.AutoModelForCausalLM.from_pretrained', 'pretrained_model_name_or_path': '${model_name}'}, 'generation_kwargs': {'temperature': 0, 'max_new_tokens': 300}}, 'model_name': 'EleutherAI/gpt-neo-2.7B', 'task_name': 'mrpc', 'output_file': 'output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64/pred.json', 'batch_size': 8, 'dataset_reader': {'_target_': 'src.dataset_readers.inference_dsr.InferenceDatasetReader', 'dataset_path': 'output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64/train_retrieved.json', 'dataset_split': None, 'task_name': '${task_name}', 'model_name': '${model_name}', 'n_tokens': 1600, 'field': 'gen_a', 'ds_size': None, 'index_reader': '${index_reader}'}, 'index_reader': {'_target_': 'src.dataset_readers.index_dsr.IndexDatasetReader', 'task_name': '${task_name}', 'model_name': '${model_name}', 'field': 'qa', 'dataset_path': 'index_data/mrpc/index_dataset.json', 'dataset_split': None, 'ds_size': None}}\n",
            "2024-01-23 17:27:45.816410: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-23 17:27:45.816460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-23 17:27:45.818134: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-23 17:27:47.020005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-01-23 17:27:48,169][datasets][INFO] - PyTorch version 2.1.0+cu121 available.\n",
            "[2024-01-23 17:27:48,170][datasets][INFO] - TensorFlow version 2.15.0 available.\n",
            "[2024-01-23 17:27:48,171][datasets][INFO] - JAX version 0.4.23 available.\n",
            "[2024-01-23 17:27:48,375][src.dataset_readers.dataset_wrappers.base_dsw][INFO] - Loading dataset from index_data/mrpc/index_dataset.json, size 13470\n",
            "Map: 100% 13470/13470 [00:07<00:00, 1892.72 examples/s]\n",
            "[2024-01-23 17:27:55,936][src.dataset_readers.dataset_wrappers.base_dsw][INFO] - Loading dataset from output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64/train_retrieved.json, size 1\n",
            "Map: 100% 1/1 [00:00<00:00, 122.41 examples/s]\n",
            "[2024-01-23 17:27:56,677][__main__][INFO] - Statistics after sharding: \n",
            "[2024-01-23 17:27:56,681][src.utils.statistics][INFO] - length of main dataset: count     1.0\n",
            "mean     87.0\n",
            "std       NaN\n",
            "min      87.0\n",
            "25%      87.0\n",
            "50%      87.0\n",
            "75%      87.0\n",
            "max      87.0\n",
            "dtype: float64\n",
            "[2024-01-23 17:27:58,203][src.utils.statistics][INFO] - length of index dataset: count    13470.000000\n",
            "mean        74.183148\n",
            "std         44.885200\n",
            "min         20.000000\n",
            "25%         49.000000\n",
            "50%         64.000000\n",
            "75%         87.000000\n",
            "max       1343.000000\n",
            "dtype: float64\n",
            "  0% 0/1 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "[2024-01-23 17:28:29,008][__main__][INFO] - Prompt: On March 10 , 2017 , Staples entered into a share purchase agreement pursuant to which Platinum Equity ( Platinum ) agreed to purchase 100 % of the outstanding shares related to STAPLES INC s operations in Australia and New Zealand . Can we say \"org:gpe:operations_in\"? org:gpe:operations_in\n",
            "In connection with the acquisition of the remaining 51 % of the partnership interests in the Terranomics Crossroads Associates , LP and the acquisition of 100 % of the equity interest in SARM Five Points Plaza LLC in September 2013 , Retail Opportunity Investments Partnership , LP entered into Tax Protection Agreements with certain limited partners of the Operating Partnership . Can we say \"org:date:acquired_on\"? org:date:acquired_on\n",
            "Archrock , Inc. common stock is traded on the New York Stock Exchange under the symbol AROC . Can we say \"no_relation\"? no_relation\n",
            "Effective September 29 , 2017 , ALLTEMP , INC . entered into a Share Exchange Agreement with Spider Investments , LLC , a company controlled by the former controlling shareholder of ALLTEMP , INC . prior to the Merger , which provided for Spider Investments , LLC to acquire all of the issued and outstanding shares of capital stock of ALLTEMP , INC . s wholly - owned subsidiary , Venture Track , Inc , a Delaware corporation , in exchange for 200,000 shares of ALLTEMP , INC . s common stock . Can we say \"org:org:subsidiary_of\"? org:org:subsidiary_of\n",
            "The New York Stock Exchange is the principal market for PEPSICO INC common stock , which is also listed on the Chicago Stock Exchange and SIX Swiss Exchange . Can we say \"no_relation\"? no_relation\n",
            "Under the terms of the NLEX purchase agreement , Heritage Global Inc. will pay , to the former owner of NLEX , 50 % of the Net Profits ( as defined in the NLEX stock purchase agreement ) of NLEX for each of the four years following the closing . Can we say \"no_relation\"? no_relation\n",
            "On January 13 , 2016 , iBio , Inc. entered into a share purchase agreement with Eastern pursuant to which Eastern agreed to purchase 3,500,000 shares of iBio , Inc. s common stock at a price of $ 0.622 per share . Can we say \"org:org:shares_of\"? org:org:shares_of\n",
            "HILLS BANCORPORATION common stock is not listed on the NASDAQ stock market or any other stock exchange . Can we say \"no_relation\"? no_relation\n",
            "INTERGROUP CORP 's Common Stock is listed and trades on the NASDAQ Capital Market tier of the NASDAQ Stock Market , LLC under the symbol : INTG . Can we say \"no_relation\"? no_relation\n",
            "Pursuant to the Agreement , China Teletech Holding Inc will purchase , in an aggregate , 51 % of all the outstanding capital of SJD in exchange for 20 million newly issued shares of China Teletech Holding Inc s common stock . Can we say \"org:org:shares_of\"? org:org:shares_of\n",
            "Pursuant to the Merger Agreement , UnitedHealth Group has agreed to acquire all of the outstanding shares of Surgical Care Affiliates , Inc. s common stock for $ 57.00 per share , to be funded with a combination of cash and UnitedHealth Group common stock , as set forth in the Merger Agreement . Can we say \"org:org:acquired_by\"? \n",
            "[2024-01-23 17:28:29,009][__main__][INFO] - Generated: 0\n",
            "[2024-01-23 17:28:29,009][__main__][INFO] - Number of ICE: 10\n",
            "100% 1/1 [00:01<00:00,  1.14s/it]\n",
            "[2024-01-23 17:28:29,009][src.utils.misc][INFO] - Saving to output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64/pred.jsontmp_cuda.bin\n",
            "[2024-01-23 17:28:29,009][__main__][INFO] - Average number of in-context examples after truncating is 10.0\n",
            "[2024-01-23 17:28:29,010][src.utils.misc][INFO] - Saving to output/epr/mrpc/EleutherAI/gpt-neo-2.7B/bert-fix_ctx-shared-bs64/pred.json\n"
          ]
        }
      ],
      "source": [
        "!sh scripts/run_epr.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOxo5x0GFilg"
      },
      "outputs": [],
      "source": [
        "api_key1 = \"YOUR_OPENAI_KEY_HERE\"\n",
        "from openai import OpenAI\n",
        "def chat(text,ins):\n",
        "  client = OpenAI(api_key =api_key1 )\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "    #model=\"gpt-4-1106-preview\",\n",
        "    #model=\"gpt-3.5-turbo\",\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": ins},\n",
        "    {\"role\": \"user\", \"content\": text}\n",
        "    ])\n",
        "  return (completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBuIIGnH_4Mk",
        "outputId": "81ea7a12-989b-44bc-86b5-16f6798bd171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INSTRUCTION\tI am a knowledgable person. I will solve the relation extraction task. Given the context and two entities, i will first consider whether the most precise relation between two entities belong to any following class, if yes i will output the most precise relation, otherwise output will be no_relation\n",
            "org:org:agreement_with\twhen org enter or plan to enter into an agreement with org Y for matters like settlement\n",
            "  license etc\n",
            "  org:org:shares_of\twhen an org holds some shares of another org or it invests in the other org through IPO\n",
            "  stocks\n",
            " voting rights etc\n",
            "  org:org:acquired_by\twhen an org is acquired by another org\n",
            "  org:org:subsidiary_of\twhen an org is subsidiary of another org\n",
            "Effective September 29 , 2017 , ALLTEMP , INC . entered into a Share Exchange Agreement with Spider Investments , LLC , a company controlled by the former controlling shareholder of ALLTEMP , INC . prior to the Merger , which provided for Spider Investments , LLC to acquire all of the issued and outstanding shares of capital stock of ALLTEMP , INC . s wholly - owned subsidiary , Venture Track , Inc , a Delaware corporation , in exchange for 200,000 shares of ALLTEMP , INC . s common stock .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Venture Track , Inc', 'ORG_2': 'ALLTEMP , INC . s'}\n",
            "Answer: org:org:subsidiary_of\n",
            "On January 13 , 2016 , iBio , Inc. entered into a share purchase agreement with Eastern pursuant to which Eastern agreed to purchase 3,500,000 shares of iBio , Inc. s common stock at a price of $ 0.622 per share .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Eastern', 'ORG_2': 'iBio , Inc. s'}\n",
            "Answer: org:org:shares_of\n",
            "Pursuant to the Agreement , China Teletech Holding Inc will purchase , in an aggregate , 51 % of all the outstanding capital of SJD in exchange for 20 million newly issued shares of China Teletech Holding Inc s common stock .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'China Teletech Holding Inc s', 'ORG_2': 'SJD'}\n",
            "Answer: org:org:shares_of\n",
            "\n",
            "\n",
            "The consolidated financial statements include the accounts of Lithium Exploration Group , Inc , its wholly - owned subsidiary Alta Disposal Ltd. and its 51 % owned subsidiary Alta Disposal Morinville Ltd. ( formerly Bluetap Resources Ltd. ) .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Alta Disposal Morinville Ltd.', 'ORG_2': 'Lithium Exploration Group , Inc'}\n",
            "Answer: org:org:subsidiary_of\n",
            "\n",
            "\n",
            "Cytosorbents Corp , through its subsidiary CytoSorbents Medical Inc. ( formerly known as CytoSorbents , Inc. ) , is engaged in the research , development and commercialization of medical devices with its blood purification technology platform which incorporates a proprietary adsorbent , porous polymer technology .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'CytoSorbents Medical Inc.', 'ORG_2': 'Cytosorbents Corp'}\n",
            "Answer: org:org:subsidiary_of\n",
            "\n",
            "\n",
            "These financial statements include the accounts of CHEETAH ENTERPRISES , INC . and the wholly - owned subsidiary , Cheetah Autos S.A.\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Cheetah Autos S.A.', 'ORG_2': 'CHEETAH ENTERPRISES , INC .'}\n",
            "Answer: org:org:subsidiary_of\n",
            "\n",
            "\n",
            "On March 23 , 2017 , INVENTURE FOODS , INC . announced the sale of certain assets , properties and rights of INVENTURE FOODS , INC . wholly owned subsidiary , Fresh Frozen Foods , to Pictsweet , pursuant to the Purchase Agreement .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Fresh Frozen Foods', 'ORG_2': 'INVENTURE FOODS , INC .'}\n",
            "Answer: org:org:subsidiary_of\n",
            "\n",
            "\n",
            "Philip Morris International Inc. subsidiary PMI believe that the findings of liability and damages were incorrect and should ultimately be set aside on any one of many grounds , including the following : ( i ) holding that defendants violated Quebec law by failing to warn class members of the risks of smoking even after the court found that class members knew , or should have known , of the risks , ( ii ) finding that plaintiffs were not required to prove that defendants alleged misconduct caused injury to each class member in direct contravention of binding precedent , ( iii ) creating a factual presumption , without any evidence from class members or otherwise , that defendants alleged misconduct caused all smoking by all class members , ( iv ) relying on epidemiological evidence that did not meet recognized scientific standards , and ( v ) awarding punitive damages to punish defendants without proper consideration as to whether punitive damages were necessary to deter future misconduct .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Philip Morris International Inc.', 'ORG_2': 'believe'}\n",
            "Answer: org:org:subsidiary_of\n",
            "\n",
            "\n",
            "As a result , the Private Co. shareholders own approximately 76.97 % of eWELLNESS HEALTHCARE Corp issued and outstanding common stock , after giving effect to CEO Stock Actions .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Private Co.', 'ORG_2': 'eWELLNESS HEALTHCARE Corp'}\n",
            "Answer: no_relation\n",
            "\n",
            "\n",
            "Under the registration rights agreement , Blackstone Group L.P. agreed to register the exchange of Blackstone Holdings Partnership Units for common units by Blackstone Group L.P. holders of Blackstone Holdings Partnership Units .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Blackstone Group L.P.', 'ORG_2': 'Blackstone Holdings Partnership Units'}\n",
            "Answer: no_relation\n",
            "\n",
            "\n",
            "HYSTER - YALE MATERIALS HANDLING , INC , through HYG , designs , engineers , manufactures , sells and services a comprehensive line of lift trucks , attachments and aftermarket parts marketed globally primarily under the Hyster and Yale brand names , mainly to independent Hyster and Yale retail dealerships .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Hyster', 'ORG_2': 'HYG'}\n",
            "Answer: no_relation\n",
            "\n",
            "\n",
            "Anti - takeover provisions in CLOUD PEAK ENERGY INC . charter documents and other aspects of CLOUD PEAK ENERGY INC . structure may discourage , delay or prevent a change in control of CLOUD PEAK ENERGY INC . company and may adversely affect the trading price of CPE Inc. s common stock .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'CPE Inc. s', 'ORG_2': 'CLOUD PEAK ENERGY INC .'}\n",
            "Answer: no_relation\n",
            "\n",
            "\n",
            "On October 14 , 2015 , SPYR , Inc. was named as a defendant in a case filed in the United States District Court for the District of Delaware case : Zakeni Limited v. SPYR , Inc , f / k / a Eat at Joe s , Ltd.\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'SPYR , Inc.', 'ORG_2': 'Zakeni Limited'}\n",
            "Answer: no_relation\n",
            "\n",
            "\n",
            "On September 30 , 2016 , Dongxing International Inc. ( the Company or Dongxing ) entered into and closed a share exchange agreement with Central Dynamic Holdings Limited ( Central Dynamic ) and its shareholders .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Dongxing International Inc.', 'ORG_2': 'Central Dynamic Holdings Limited'}\n",
            "Answer: org:org:agreement_with\n",
            "\n",
            "\n",
            "Unless extended or earlier terminated under the terms and conditions of Hughes Satellite Systems Corp agreement with DISH Network for the QuetzSat-1 satellite , the initial service term will expire in November 2021 .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Hughes Satellite Systems Corp', 'ORG_2': 'DISH Network'}\n",
            "Answer: org:org:agreement_with\n",
            "\n",
            "\n",
            "In such event , it is likely IMMUNOMEDICS INC could never receive any additional milestone payments or royalties that IMMUNOMEDICS INC are eligible to receive under IMMUNOMEDICS INC agreement with UCB , and IMMUNOMEDICS INC ability to fund the development and testing of IMMUNOMEDICS INC other product candidates could be adversely affected .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'IMMUNOMEDICS INC', 'ORG_2': 'UCB'}\n",
            "Answer: org:org:agreement_with\n",
            "\n",
            "\n",
            "Hawaii Gas entered into licensing agreements with Utility Service Partners , Inc. and America s Water Heater Rentals , LLC , both indirect subsidiaries of Macquarie Group Limited , to enable these entities to offer products and services to Hawaii Gas s customer base .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Hawaii Gas', 'ORG_2': 'Utility Service Partners , Inc.'}\n",
            "Answer: org:org:agreement_with\n",
            "\n",
            "\n",
            "In addition to Immune Design Corp. current agreements with MedImmune , Sanofi and Sanofi Pasteur , a part of Immune Design Corp. strategy is to enter into additional product development collaborations in the future , including collaborations with major biotechnology or pharmaceutical companies .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Immune Design Corp.', 'ORG_2': 'MedImmune'}\n",
            "Answer: org:org:agreement_with\n",
            "\n",
            "\n",
            "On August 4 , 2017 , MetLife , Inc. completed the separation of Brighthouse Financial , Inc. and its subsidiaries ( Brighthouse ) through a distribution of 96,776,670 shares of the 119,773,106 shares of Brighthouse Financial , Inc. common stock outstanding , representing 80.8 % of those shares , to MetLife , Inc. common shareholders ( the Separation ) .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'MetLife , Inc.', 'ORG_2': 'Brighthouse Financial , Inc.'}\n",
            "Answer: org:org:shares_of\n",
            "\n",
            "\n",
            "LinnCo , LLC are a controlled company because LINN Energy holds LinnCo , LLC sole voting share and has the sole power to elect LinnCo , LLC board of directors .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'LINN Energy', 'ORG_2': 'LinnCo , LLC'}\n",
            "Answer: org:org:shares_of\n",
            "\n",
            "\n",
            "Included in Sky s results for fiscal 2015 was TWENTY - FIRST CENTURY FOX , INC . s proportionate share of approximately $ 790 million of Sky s gains related to the sale of its investments in NGC Network International , LLC and NGC Network Latin America , LLC ( collectively , NGC International ) , Sky Betting Gaming ( Sky Bet ) and ITV plc .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'TWENTY - FIRST CENTURY FOX , INC . s', 'ORG_2': 'Sky'}\n",
            "Answer: org:org:shares_of\n",
            "\n",
            "\n",
            "Loan Agreements with LG Capital Funding , LLC On February 27 , 2014 , Lithium Exploration Group , Inc. entered into another securities purchase agreement with LG Capital Funding , LLC .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Lithium Exploration Group , Inc.', 'ORG_2': 'LG Capital Funding , LLC'}\n",
            "Answer: org:org:shares_of\n",
            "\n",
            "\n",
            "Hannon Armstrong Sustainable Infrastructure Capital , Inc. common stock is listed on the New York Stock Exchange ( NYSE ) under the symbol HASI .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Hannon Armstrong Sustainable Infrastructure Capital , Inc.', 'ORG_2': 'HASI'}\n",
            "Answer: org:org:shares_of\n",
            "\n",
            "\n",
            "On July 22 , 2015 , eWELLNESS HEALTHCARE Corp s wholly owned subsidiary , eWellness Corporation , was merged into eWELLNESS HEALTHCARE Corp and , therefore , no longer exists as a separate entity .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'eWellness Corporation', 'ORG_2': 'eWELLNESS HEALTHCARE Corp'}\n",
            "Answer: org:org:acquired_by\n",
            "\n",
            "\n",
            "For example , Alteryx , Inc. agreed to issue shares of Alteryx , Inc. Class A common stock with an aggregate value of up to $ 2.3 million upon the achievement of certain milestones in connection with Alteryx , Inc. acquisition of Semanta , of which 12,492 shares of Class A common stock were issued in August 2017 upon partial satisfaction of certain milestones .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Semanta', 'ORG_2': 'Alteryx , Inc.'}\n",
            "Answer: org:org:acquired_by\n",
            "\n",
            "\n",
            "On September 2 , 2014 , CPI Card Group Inc , through its wholly - owned subsidiary , CPI Acquisition , Inc , purchased EFT Source , Inc.\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'EFT Source , Inc.', 'ORG_2': 'CPI Acquisition , Inc'}\n",
            "Answer: org:org:acquired_by\n",
            "\n",
            "\n",
            "As part of the Stratiform acquisition , PCM , INC . agreed to pay certain contingent earn - out consideration related to years ending December 31 , 2017 , 2018 and 2019 ( each year the measurement period ) , payable 90 days in arrears following each measurement period .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Stratiform', 'ORG_2': 'PCM , INC .'}\n",
            "Answer: org:org:acquired_by\n",
            "\n",
            "\n",
            "On December 14 , 2016 , SOUTHWEST BANCORP INC entered into a Merger Agreement with Simmons First National Corporation ( Simmons ) , an Arkansas corporation , pursuant to which , and subject to its terms and conditions , Simmons will acquire all of SOUTHWEST BANCORP INC outstanding capital stock for $ 95.0 million in cash and 7,250,000 shares of Simmons s common stock , subject to potential adjustments .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'SOUTHWEST BANCORP INC', 'ORG_2': 'Simmons'}\n",
            "Answer: org:org:acquired_by\n",
            "\n",
            "Pursuant to the Merger Agreement , UnitedHealth Group has agreed to acquire all of the outstanding shares of Surgical Care Affiliates , Inc. s common stock for $ 57.00 per share , to be funded with a combination of cash and UnitedHealth Group common stock , as set forth in the Merger Agreement .\n",
            "{'rel_group': 'ORG-ORG', 'ORG_1': 'Surgical Care Affiliates , Inc. s', 'ORG_2': 'UnitedHealth Group'}\n",
            "Answer: \n",
            "##########\n",
            "ChatCompletionMessage(content='no_relation', role='assistant', function_call=None, tool_calls=None)\n",
            "##########\n",
            "ChatCompletionMessage(content='org:org:acquired_by', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "icl_prompt, instruction = generate_final_prompt()\n",
        "\n",
        "test_data1= copy.deepcopy(test_data)\n",
        "del test_data1[\"sentence\"]\n",
        "del test_data1[\"relation\"]\n",
        "print(instruction)\n",
        "print(icl_prompt)\n",
        "print(\"##########\")\n",
        "print(chat(test_prompt,instruction))\n",
        "print(\"##########\")\n",
        "print(chat(icl_prompt,instruction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fjBmhpBFF_2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Org:Org:Acquired_By\n",
        "{\"sentence\": \"Pursuant to the Merger Agreement , UnitedHealth Group has agreed to acquire all of the outstanding shares of Surgical Care Affiliates , Inc. s common stock for $ 57.00 per share , to be funded with a combination of cash and UnitedHealth Group common stock , as set forth in the Merger Agreement .\", \"rel_group\": \"ORG-ORG\", \"relation\": \"org:org:acquired_by\", \"ORG_1\": \"Surgical Care Affiliates , Inc. s\", \"ORG_2\": \"UnitedHealth Group\"}\n",
        "Org:GPE:Headquartered_In\n",
        "{\"sentence\": \"The peer group consists of all publicly traded Commercial Banks and Thrifts headquartered in New Jersey , New York , Ohio and Pennsylvania with total assets of $ 750 million to $ 3.5 billion as of the end of the four consecutive calendar quarters ending with the third quarter of each calendar year following the Award Date .\", \"rel_group\": \"ORG-GPE\", \"relation\": \"org:gpe:headquartered_in\", \"ORG\": \"Commercial Banks and Thrifts\", \"GPE\": \"Pennsylvania\"}\n",
        "Person:Organization:Member_Of\n",
        "{\"sentence\": \"Ms. Lee serves on the board of directors of the Alvin Ailey American Dance Theater and the Paley Center .\", \"rel_group\": \"PERSON-ORG\", \"relation\": \"pers:org:member_of\", \"PERSON\": \"Lee\", \"ORG\": \"the Alvin Ailey American Dance Theater\"}\n",
        "No Relation\n",
        "{\"sentence\": \"On July 10 , 2017 , Lead Plaintiff filed an amended federal securities class action complaint ( the Amended Complaint ) against Rentech , Inc , Keith Forman , and Jeffrey Spain .\", \"rel_group\": \"PERSON-ORG\", \"relation\": \"no_relation\", \"PERSON\": \"Jeffrey Spain\", \"ORG\": \"Rentech , Inc\"}\n",
        "\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}